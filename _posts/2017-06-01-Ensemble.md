---
title:  Ensemble
date:   2017-06-01 22:37:00
categories: Deep Learning, Ensemble
---

```python
import numpy as np
import pickle as plk
with open('Xbasic_xgb.p', 'rb') as f:
    Xbasic= plk.load(f)
    
    
Xbasic_train = Xbasic['Xbasic_train'] 
Xbasic_val = Xbasic['Xbasic_val']
Xbasic_test = Xbasic['Xbasic_test']
y_train = Xbasic['y_train']
y_val = Xbasic['y_val']
test_xgb = Xbasic['test_xgb']
val_xgb = Xbasic['val_xgb']
test_id = Xbasic['test_id']
```


```python
df_train = pd.read_csv('../input/train.csv')
df_test = pd.read_csv('../input/test.csv')
```


```python
# Add xgb pred with basic features
print(Xbasic_val.shape)
print(Xbasic_test.shape)
Xbasic_val = np.hstack((Xbasic_val, val_xgb.T))
Xbasic_test = np.hstack((Xbasic_test, test_xgb.T))
print(Xbasic_val.shape)
print(Xbasic_test.shape)
```

    (80858, 43)
    (2345796, 43)
    (80858, 48)
    (2345796, 48)



```python
for i in [1, 2, 3, 4, 5, 6]:
    with open('LSTM_CNN_basic' + str(i) + '.p', 'rb') as f:
        deep_feats = plk.load(f)
        print(deep_feats['pred_val'].shape)
        if np.sum(np.squeeze(y_val) - deep_feats['y_val'][:len(y_val)]) != 0:
            print('WARNING!!!')
        else:
            
            Xbasic_val = np.hstack((Xbasic_val, np.expand_dims(deep_feats['pred_val'], axis = 1)))
            Xbasic_test = np.hstack((Xbasic_test, np.expand_dims(deep_feats['pred_test'], axis = 1)))
```

    (80858,)
    (80858,)
    (80858,)
    (80858,)
    (80858,)
    (80858,)



```python
with open('spacy.p', 'rb') as f:
    deep_feats = plk.load(f)
    print(deep_feats['pred_val'].shape)
    print(deep_feats['pred_test'].shape)
    print(Xbasic_test.shape)
    print(np.sum(np.squeeze(y_val) - deep_feats['y_val'][:len(y_val)]))
      
    Xbasic_val = np.hstack((Xbasic_val, np.expand_dims(deep_feats['pred_val'], axis = 1)))
    Xbasic_test = np.hstack((Xbasic_test, np.expand_dims(deep_feats['pred_test'], axis = 1)))
```

    (80858,)
    (404290,)
    (2345796, 54)
    0



    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    <ipython-input-272-1949ea99a806> in <module>()
          7 
          8     Xbasic_val = np.hstack((Xbasic_val, np.expand_dims(deep_feats['pred_val'], axis = 1)))
    ----> 9     Xbasic_test = np.hstack((Xbasic_test, np.expand_dims(deep_feats['pred_test'], axis = 1)))
    

    /usr/local/lib/python3.4/site-packages/numpy/core/shape_base.py in hstack(tup)
        286         return _nx.concatenate(arrs, 0)
        287     else:
    --> 288         return _nx.concatenate(arrs, 1)
        289 
        290 def stack(arrays, axis=0):


    ValueError: all the input array dimensions except for the concatenation axis must match exactly



```python
np.corrcoef(y_val, Xbasic_val[:,53])
```


```python
print(Xbasic_val.shape)
print(Xbasic_test.shape)
```

    (80858, 54)
    (2345796, 54)



```python
# Further split
from sklearn.model_selection import train_test_split
Xbasic_val_train, Xbasic_val_val, y_val_train, y_val_val = train_test_split(Xbasic_val, 
                                                            y_val,
                                                            stratify = y_val,
                                                            test_size=0.4, 
                                                            random_state=1992)
```


```python
import xgboost as xgb
weight_val_train = (1- y_val_train) * 1.309028344 + y_val_train * 0.472001959
weight_val_val = (1- y_val_val) * 1.309028344 + y_val_val * 0.472001959

dTrain = xgb.DMatrix(Xbasic_val_train, label=y_val_train
                     , weight = weight_val_train
                    )
dVal = xgb.DMatrix(Xbasic_val_val, label=y_val_val
                   , weight = weight_val_val
                  )
dTest = xgb.DMatrix(Xbasic_test)
```


```python
print(Xbasic_val.shape)
print(Xbasic_test.shape)
```

    (80858, 54)
    (2345796, 54)



```python
xgb_params = {
    'objective': 'binary:logistic',
    'booster': 'gbtree',
    'eval_metric': ['error', 'logloss'],
    'eta': 0.01, 
    'max_depth': 8,
    'subsample': 0.8,
    'nthread':4,
    'silent': 1,
    #'colsample_bytree': 1,
    #'min_child_weight': 5,
}
bst = xgb.train(xgb_params, dTrain, 
                10000,  [(dTrain,'train'), (dVal,'val')], 
                verbose_eval= 50, 
                early_stopping_rounds=50, )
```

    [0]	train-error:0.085008	train-logloss:0.685625	val-error:0.102988	val-logloss:0.685874
    Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.
    
    Will train until val-logloss hasn't improved in 50 rounds.
    [50]	train-error:0.073719	train-logloss:0.436578	val-error:0.093472	val-logloss:0.447329
    [100]	train-error:0.072778	train-logloss:0.317377	val-error:0.092986	val-logloss:0.336158
    [150]	train-error:0.07189	train-logloss:0.253112	val-error:0.092372	val-logloss:0.278618
    [200]	train-error:0.07078	train-logloss:0.216311	val-error:0.092792	val-logloss:0.247409
    [250]	train-error:0.06989	train-logloss:0.194274	val-error:0.09279	val-logloss:0.230099
    [300]	train-error:0.069487	train-logloss:0.180862	val-error:0.092728	val-logloss:0.220428
    [350]	train-error:0.068797	train-logloss:0.172171	val-error:0.092773	val-logloss:0.214989
    [400]	train-error:0.067822	train-logloss:0.166408	val-error:0.092768	val-logloss:0.21188
    [450]	train-error:0.067101	train-logloss:0.162392	val-error:0.092561	val-logloss:0.210201
    [500]	train-error:0.066196	train-logloss:0.159174	val-error:0.092746	val-logloss:0.20921
    [550]	train-error:0.065307	train-logloss:0.156564	val-error:0.092712	val-logloss:0.20868
    [600]	train-error:0.063968	train-logloss:0.154021	val-error:0.092443	val-logloss:0.208441
    [650]	train-error:0.062701	train-logloss:0.151682	val-error:0.093001	val-logloss:0.208368
    [700]	train-error:0.060901	train-logloss:0.149292	val-error:0.092924	val-logloss:0.208364
    Stopping. Best iteration:
    [673]	train-error:0.061933	train-logloss:0.150615	val-error:0.092866	val-logloss:0.208345
    



```python
# Predict
import pandas as pd

pred = bst.predict(dTest, ntree_limit = bst.best_ntree_limit)
```


```python
df_sub = pd.DataFrame({
        'is_duplicate': pred,
        'test_id': test_id 
    })
df_sub.head()
df_sub.to_csv('~/Desktop/submission_sl.csv', index=False)
```


```python
from xgboost import plot_importance
import matplotlib as plt
from matplotlib import *
%matplotlib inline
plt.rcParams['figure.figsize'] = (20.0, 30.0) # set default size of plots
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'


plot_importance(bst)
pyplot.show()
```


![png](SL_files/SL_13_0.png)



```python

```
